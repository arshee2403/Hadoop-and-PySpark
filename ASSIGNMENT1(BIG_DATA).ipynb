{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ASSIGNMENT1(BIG DATA).ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lOJLwShNKjCQ",
        "colab_type": "text"
      },
      "source": [
        "GET THE DATA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z-2gTkPJBY-p",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "outputId": "7e924a6a-f1b3-42cb-d648-fa0923f4624c"
      },
      "source": [
        "!wget --no-check-certificate http://qwone.com/~jason/20Newsgroups/20news-bydate.tar.gz -O /tmp/20news-bydate.tar.gz"
      ],
      "execution_count": 219,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-08-11 17:37:13--  http://qwone.com/~jason/20Newsgroups/20news-bydate.tar.gz\n",
            "Resolving qwone.com (qwone.com)... 108.20.201.166\n",
            "Connecting to qwone.com (qwone.com)|108.20.201.166|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 14464277 (14M) [application/x-gzip]\n",
            "Saving to: ‘/tmp/20news-bydate.tar.gz’\n",
            "\n",
            "/tmp/20news-bydate. 100%[===================>]  13.79M  6.60MB/s    in 2.1s    \n",
            "\n",
            "2020-08-11 17:37:15 (6.60 MB/s) - ‘/tmp/20news-bydate.tar.gz’ saved [14464277/14464277]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AdrQT4_DKxe_",
        "colab_type": "text"
      },
      "source": [
        "IMPORT MODULES"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e_lpyCN-CHD7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "e1d6704f-def7-47ac-8f81-3f2cfa9bd597"
      },
      "source": [
        "import os\n",
        "import tarfile\n",
        "import re\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "sw = stopwords.words('english') \n",
        "import operator"
      ],
      "execution_count": 220,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sfhp353rK6eg",
        "colab_type": "text"
      },
      "source": [
        "EXTRACT THE FILE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vDbr2V2fCJGQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "file_ref = tarfile.open('/tmp/20news-bydate.tar.gz')\n",
        "file_ref.extractall('/tmp')\n",
        "file_ref.close()"
      ],
      "execution_count": 221,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5FdOZ5tYK83C",
        "colab_type": "text"
      },
      "source": [
        "STORE THE DATA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vT6kAWVqCMAf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = []\n",
        "for root, dirs, files in os.walk(\"/tmp/20news-bydate-train\", topdown=False):\n",
        "  for name in files:\n",
        "    with open(os.path.join(root, name), 'r',encoding=\"utf8\", errors='ignore') as f:\n",
        "      text = f.read()\n",
        "      data.append(text)\n",
        "      f.close()"
      ],
      "execution_count": 222,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-UjHCwUYCN7I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# data[0]"
      ],
      "execution_count": 223,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Es4LsaeYCQ4T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# len(data)"
      ],
      "execution_count": 224,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wx6WwcJ2LDEG",
        "colab_type": "text"
      },
      "source": [
        "PREPROCESSING STEPS :\n",
        "\n",
        "\n",
        "*   Convert into lowercase\n",
        "*   Keep only text\n",
        "*   Remove stopwords\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "shYIAxJXClTk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def remove_stopwords(text):\n",
        "  filtered_words = [w for w in text.split()  if ((not w in sw) and (len(w)>1))]\n",
        "  return \" \".join(filtered_words)\n",
        "\n",
        "def preprocess(text):\n",
        "  text = list(map(lambda x:x.lower(),text))\n",
        "  text = list(map(lambda x : re.sub(\"[^a-zA-Z]\", \" \",x),text)) \n",
        "  text = list(map(remove_stopwords,text))\n",
        "  return text"
      ],
      "execution_count": 225,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z-kwcwF2LW24",
        "colab_type": "text"
      },
      "source": [
        "PREPROCESS THE DATA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IyZ_atgxDUbX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cleaned = preprocess(data)\n",
        "# cleaned[:10]"
      ],
      "execution_count": 226,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oWFPJG1ALfam",
        "colab_type": "text"
      },
      "source": [
        "CREATE A NESTED DICTIONARY\n",
        "\n",
        "FIND FREQUENCY OF EACH WORD IN EACH DOCUMENT\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1fGBjKgzcypr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def term_doc_frequency(data):\n",
        "  final_dict = {}\n",
        "  for i in range(len(data)):\n",
        "    doc_dict = {} \n",
        "    for w in data[i].split():\n",
        "        try:\n",
        "            doc_dict[w].add(i)\n",
        "        except:\n",
        "            doc_dict[w] = {i}\n",
        "    for j in doc_dict:\n",
        "      doc_dict[j] = len(doc_dict[j])\n",
        "    final_dict[i] = doc_dict\n",
        "  return final_dict"
      ],
      "execution_count": 227,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4IgrLyWnhwfL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "final_dict = term_doc_frequency(cleaned)"
      ],
      "execution_count": 228,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OQSlNpneLt81",
        "colab_type": "text"
      },
      "source": [
        "RETRIEVE THE TOP 3 RELEVANT DOCUMENTS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kT2T0HDvKGhJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def top_3(data,final_dict,query):\n",
        "  original_query = [query]\n",
        "  processed_query = preprocess(original_query)\n",
        "  query_dict = dict(zip((processed_query[0].split()),[0]*len((processed_query[0].split()))))\n",
        "  output_dict = {}\n",
        "  for i in (list(final_dict.keys())):\n",
        "    doc = {key: final_dict[i][key] for key in final_dict[i].keys() & query_dict.keys()}\n",
        "    output_dict[i] = sum(list(doc.values()))\n",
        "  sorted_output_dict = dict(sorted(output_dict.items(), key=operator.itemgetter(1),reverse=True))\n",
        "  relevant_3 = [data[i] for i in list(sorted_output_dict.keys())[:3]] \n",
        "  return relevant_3"
      ],
      "execution_count": 229,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0CFHJKPkMwxq",
        "colab_type": "text"
      },
      "source": [
        "HIGHLIGHT THE PART OF THE DOCUMENT WHERE THE SEARCH STRING HAS OCCURED"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j4R9eFFooX20",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from termcolor import colored\n",
        "import string\n",
        "def color_text(text,words):\n",
        "  new = []\n",
        "  text = text.lower().split()\n",
        "  for t in text:\n",
        "    word = \"\".join(re.findall(\"[a-z]+\", t))\n",
        "    if word in words:\n",
        "      new.append(colored(t, 'white', 'on_blue'))\n",
        "    else:\n",
        "      new.append(t)\n",
        "  return ' '.join(new)"
      ],
      "execution_count": 230,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J1N_MOllQk_t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#@title What would you like to search? \n",
        "#amusing atheists and agnostics organization\n",
        "original_query= 'amusing atheists and agnostics organization' #@param {type:\"string\"}\n",
        "query = original_query.lower()\n",
        "output = top_3(data,final_dict,original_query)"
      ],
      "execution_count": 231,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1j2MwvRW0zT8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 188
        },
        "outputId": "974a21bb-7f6c-433d-86e5-00426d0a53dd"
      },
      "source": [
        "for i in output:\n",
        "  print(color_text(i,query.split()))\n",
        "  print('\\n')"
      ],
      "execution_count": 233,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "from: madhaus@netcom.com (maddi hausmann) subject: re: \u001b[44m\u001b[37mamusing\u001b[0m \u001b[44m\u001b[37matheists\u001b[0m \u001b[44m\u001b[37mand\u001b[0m \u001b[44m\u001b[37magnostics\u001b[0m \u001b[44m\u001b[37morganization:\u001b[0m society for putting things on top of other things lines: 40 timmbake@mcl.ucsb.edu (bake timmons) writes: > >ok, you have disproved one thing, but you failed to \"nail\" me. > >see, nowhere in my post did i claim that something _must_ be believed in. here >are the three possibilities: > > 1) god exists. > 2) god does not exist. > 3) i don't know. > >my attack was on strong atheism, (2). since i am (3), i guess by what you said >below that makes me a weak atheist. [snip] >first of all, you seem to be a reasonable guy. why not try to be more honest \u001b[44m\u001b[37m>and\u001b[0m include my sentence afterwards that honest, it just ended like that, i swear! hmmmm...i recognize the warning signs...alternating polite \u001b[44m\u001b[37mand\u001b[0m rude...coming into newsgroup with huge chip on shoulder...calls people names \u001b[44m\u001b[37mand\u001b[0m then makes nice...whirrr...click...whirrr \"clam\" bake timmons = bill \"shit stirrer connor\" q.e.d. whirr click whirr...frank o'dwyer might also be contained in that shell...pop stack to determine...whirr...click..whirr \"killfile\" keith allen schneider = frank \"closet theist\" o'dwyer = the mind reels. maybe they're all bobby mozumder. -- maddi hausmann madhaus@netcom.com centigram communications corp san jose california 408/428-3553 kids, please don't try this at home. remember, i post professionally.\n",
            "\n",
            "\n",
            "from: bdunn@cco.caltech.edu (brendan dunn) subject: re: \u001b[44m\u001b[37mamusing\u001b[0m \u001b[44m\u001b[37matheists\u001b[0m \u001b[44m\u001b[37mand\u001b[0m \u001b[44m\u001b[37magnostics\u001b[0m \u001b[44m\u001b[37morganization:\u001b[0m california institute of technology, pasadena lines: 8 nntp-posting-host: punisher.caltech.edu thanks to whoever posted this wonderful parody of people who post without reading the faq! i was laughing for a good 5 minutes. were there any parts of the faq that weren't mentioned? i think there might have been one or two... please don't tell me this wasn't a joke. i'm not ready to hear that yet... brendan\n",
            "\n",
            "\n",
            "from: nancyo@fraser.sfu.ca (nancy patricia o'connor) subject: re: \u001b[44m\u001b[37mamusing\u001b[0m \u001b[44m\u001b[37matheists\u001b[0m \u001b[44m\u001b[37mand\u001b[0m \u001b[44m\u001b[37magnostics\u001b[0m \u001b[44m\u001b[37morganization:\u001b[0m simon fraser university, burnaby, b.c., canada lines: 11 timmbake@mcl.ucsb.edu (bake timmons) writes: >rule #4: don't mix apples with oranges. how can you say that the >extermination by the mongols was worse than stalin? khan conquered people >unsympathetic to his cause. that was atrocious. but stalin killed millions of >his own people who loved \u001b[44m\u001b[37mand\u001b[0m worshipped _him_ \u001b[44m\u001b[37mand\u001b[0m his atheist state!! how can >anyone be worse than that? you're right. \u001b[44m\u001b[37mand\u001b[0m david koresh claimed to be a christian.\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}